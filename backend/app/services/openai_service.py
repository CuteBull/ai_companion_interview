import asyncio
from typing import List, Optional, AsyncGenerator
import logging
import base64
import mimetypes
import re
from pathlib import Path
from urllib.parse import urlparse, unquote
from openai import AsyncAzureOpenAI
from app.core.config import settings
from app.utils.token_counter import token_counter

logger = logging.getLogger(__name__)

class OpenAIService:
    def __init__(self):
        self.chat_client = AsyncAzureOpenAI(
            azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
            api_key=settings.AZURE_OPENAI_API_KEY,
            api_version=settings.AZURE_OPENAI_API_VERSION,
        )
        self.transcribe_client = AsyncAzureOpenAI(
            azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
            api_key=settings.AZURE_OPENAI_API_KEY,
            api_version=settings.AZURE_OPENAI_TRANSCRIBE_API_VERSION,
        )
        self.deployment = settings.AZURE_OPENAI_DEPLOYMENT

    def _sanitize_moment_copy(self, text: str) -> str:
        cleaned = (text or "").replace("\r\n", "\n").replace("\r", "\n").strip()
        if not cleaned:
            return ""

        cleaned = re.sub(r"^\s*(ä»Šæ—¥æ–‡æ¡ˆ|æœ‹å‹åœˆæ–‡æ¡ˆ|æ–‡æ¡ˆ)\s*[:ï¼š]\s*", "", cleaned)
        cleaned = re.sub(r"(?m)^\s*[>#\-*]+\s*", "", cleaned)
        cleaned = re.sub(r"(?m)^\s*(ä½ |ç”¨æˆ·|AIé™ªä¼´åŠ©æ‰‹|åŠ©æ‰‹)\s*[:ï¼š]\s*", "", cleaned)
        cleaned = re.sub(r"\n{3,}", "\n\n", cleaned)
        cleaned = re.sub(r"[ \t]{2,}", " ", cleaned)
        return cleaned.strip()[:220]

    def _fallback_moment_copy(
        self,
        user_text: str,
        assistant_texts: List[str],
        fallback_title: Optional[str] = None
    ) -> str:
        context = " ".join(
            " ".join((text or "").strip().split())
            for text in assistant_texts[-4:]
        )
        user_context = " ".join(user_text.strip().split())
        merged_context = f"{user_context} {context}".strip()

        if any(k in merged_context for k in ["å®å®", "å­©å­", "ç»¿ä¾¿", "æ‹‰ç»¿", "ä¾¿ä¾¿"]):
            return "è¢«å®å®çš„å°çŠ¶å†µå“äº†ä¸€è·³ï¼Œå…ˆåˆ«æ…Œï¼Œæ…¢æ…¢è§‚å¯Ÿã€‚æ„¿ä»Šæ™šéƒ½èƒ½å®‰å¿ƒä¸€ç‚¹ï¼Œæ—¥å­ä¾æ—§æ¸©æŸ”ğŸ¼"

        if any(k in merged_context for k in ["å¿ƒæƒ…ä¸å¥½", "éš¾è¿‡", "ç„¦è™‘", "å‹åŠ›", "çƒ¦", "å§”å±ˆ"]):
            return "ä»Šå¤©å¿ƒé‡Œæœ‰ç‚¹é‡ï¼Œä½†è¯´å‡ºæ¥å°±è½»äº†ä¸€äº›ã€‚æ…¢æ…¢æ¥ï¼Œæ„¿æˆ‘ä»¬éƒ½è¢«æ¸©æŸ”æ¥ä½âœ¨"

        seed = user_context or (fallback_title or "è®°ä¸‹ä»Šå¤©çš„å°å¿ƒæƒ…")
        seed = seed.replace("æ€ä¹ˆåŠ", "æ…¢æ…¢æ¥").strip("ï¼Ÿ?ã€‚")
        if len(seed) > 36:
            seed = f"{seed[:36]}â€¦"

        return f"{seed}ã€‚æŠŠå¿ƒäº‹å†™ä¸‹æ¥ï¼Œæ—¥å­ä¹Ÿä¼šä¸€ç‚¹ç‚¹å˜è½»ğŸŒ¿"

    async def generate_moment_copy(
        self,
        user_text: str,
        assistant_texts: List[str],
        fallback_title: Optional[str] = None
    ) -> str:
        """æ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡ç”Ÿæˆæœ‹å‹åœˆçŸ­æ–‡æ¡ˆã€‚"""
        if settings.MOCK_OPENAI:
            return self._fallback_moment_copy(user_text, assistant_texts, fallback_title)

        normalized_user = user_text.strip()
        normalized_assistant = [
            " ".join((text or "").strip().split())
            for text in assistant_texts
            if (text or "").strip()
        ]
        if not normalized_assistant:
            return self._fallback_moment_copy(normalized_user, normalized_assistant, fallback_title)

        system_prompt = (
            "ä½ æ˜¯ä¸­æ–‡æœ‹å‹åœˆæ–‡æ¡ˆåŠ©æ‰‹ã€‚è¯·æŠŠâ€œç”¨æˆ·è¡¨è¾¾ + é™ªä¼´åŠ©æ‰‹å›å¤â€æ•´åˆä¸ºä¸€æ®µç”¨æˆ·æ„¿æ„å‘æœ‹å‹åœˆçš„å¿ƒæƒ…å°è®°ã€‚"
            "è¦æ±‚ï¼š1-2å¥è¯ï¼Œ20-80å­—ï¼Œè¯­æ°”è‡ªç„¶æ¸©æŸ”ã€åç¬¬ä¸€äººç§°ï¼›"
            "ä¸è¦ç›´æ¥ç…§æŠ„ç”¨æˆ·åŸè¯ï¼›åªè¾“å‡ºæ–‡æ¡ˆæœ¬èº«ï¼›ä¸è¦æ ‡é¢˜ã€åˆ—è¡¨ã€markdownã€å¼•å·ã€è§’è‰²å‰ç¼€ã€‚"
        )
        assistant_block = "\n".join(
            f"å›å¤{i + 1}: {text[:320]}"
            for i, text in enumerate(normalized_assistant[-6:])
        )
        user_prompt = f"ç”¨æˆ·åŸè¯ï¼š{normalized_user[:300]}\n\né™ªä¼´åŠ©æ‰‹å›å¤ï¼š\n{assistant_block}"

        try:
            response = await self.chat_client.chat.completions.create(
                model=self.deployment,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0.8,
                max_tokens=140,
            )
            content = (response.choices[0].message.content or "").strip()
            sanitized = self._sanitize_moment_copy(content)
            if sanitized:
                return sanitized
        except Exception as exc:
            logger.warning("Generate moment copy failed, fallback enabled: %s", exc)

        return self._fallback_moment_copy(normalized_user, normalized_assistant, fallback_title)

    def _extract_upload_request_path(self, image_url: str) -> Optional[str]:
        if not image_url:
            return None

        parsed = urlparse(image_url)
        if parsed.scheme in ("http", "https"):
            request_path = unquote(parsed.path)
        else:
            request_path = unquote(image_url)

        if not request_path.startswith("/uploads/"):
            return None
        return request_path

    def _resolve_local_upload_path(self, image_url: str) -> Optional[Path]:
        """å°†æœ¬åœ°ä¸Šä¼ URLæ˜ å°„åˆ°ç£ç›˜è·¯å¾„ã€‚"""
        request_path = self._extract_upload_request_path(image_url)
        if not request_path:
            return None

        relative_path = request_path[len("/uploads/"):]
        upload_root = Path(settings.LOCAL_UPLOAD_DIR).resolve()
        candidate = (upload_root / relative_path).resolve()

        try:
            candidate.relative_to(upload_root)
        except ValueError:
            return None

        if not candidate.exists():
            return None

        return candidate

    def _prepare_image_url(self, image_url: str) -> Optional[str]:
        """å¦‚æœæ˜¯æœ¬åœ°ä¸Šä¼ å›¾ç‰‡ï¼Œè½¬æ¢ä¸ºdata URLï¼›è‹¥æ–‡ä»¶å·²å¤±æ•ˆåˆ™è·³è¿‡ã€‚"""
        is_local_upload = self._extract_upload_request_path(image_url) is not None
        local_path = self._resolve_local_upload_path(image_url)
        if not local_path:
            if is_local_upload:
                logger.warning("Skip inaccessible local upload for OpenAI: %s", image_url)
                return None
            return image_url

        try:
            mime_type, _ = mimetypes.guess_type(str(local_path))
            mime_type = mime_type or "application/octet-stream"
            encoded = base64.b64encode(local_path.read_bytes()).decode("ascii")
            return f"data:{mime_type};base64,{encoded}"
        except Exception as exc:
            logger.warning("Failed to convert local image to data URL: %s", exc)
            if is_local_upload:
                return None
            return image_url

    async def chat_completion_stream(
        self,
        messages: List[dict],
        max_completion_tokens: Optional[int] = None
    ) -> AsyncGenerator[str, None]:
        """æµå¼èŠå¤©è¡¥å…¨ï¼Œæ”¯æŒå›¾ç‰‡å’ŒéŸ³é¢‘æ–‡æœ¬è¾“å…¥ï¼Œè‡ªåŠ¨è®¡ç®—tokené™åˆ¶"""

        if settings.MOCK_OPENAI:
            user_texts = [
                (msg.get("content") or "").strip()
                for msg in messages
                if msg.get("role") == "user" and (msg.get("content") or "").strip()
            ]
            latest_user_text = user_texts[-1] if user_texts else ""
            recent_context = " ".join(user_texts[-4:])
            lowered_latest = latest_user_text.lower()
            lowered_context = recent_context.lower()

            mood_keywords = ["å¿ƒæƒ…ä¸å¥½", "éš¾è¿‡", "ä½è½", "ç„¦è™‘", "å‹åŠ›å¤§", "å§”å±ˆ", "çƒ¦"]
            mood_keywords_en = ["sad", "anxious", "stress", "down", "upset"]
            confirm_keywords = ["å¥½å‘€", "å¥½å•Š", "å¥½", "å—¯", "å¯ä»¥", "è¡Œ", "æ¥å§", "æƒ³è¯•è¯•"]
            greeting_keywords = ["ä½ å¥½", "å—¨", "åœ¨å—", "hello", "hi", "æ—©ä¸Šå¥½", "ä¸­åˆå¥½", "æ™šä¸Šå¥½"]
            relationship_keywords = ["ä¸ç†æˆ‘", "æ€ä¹ˆåŠ", "å†·æˆ˜", "åµæ¶", "è€å…¬", "ç”·æœ‹å‹", "ä¼´ä¾£", "å¯¹è±¡"]

            has_mood_context = any(k in recent_context for k in mood_keywords) or any(
                k in lowered_context for k in mood_keywords_en
            )
            has_mood_latest = any(k in latest_user_text for k in mood_keywords) or any(
                k in lowered_latest for k in mood_keywords_en
            )
            repeated_latest = len(user_texts) >= 2 and latest_user_text == user_texts[-2]
            has_greeting_latest = any(k in latest_user_text for k in greeting_keywords) or any(
                k in lowered_latest for k in ["hello", "hi"]
            )

            if not latest_user_text:
                reply = "æˆ‘åœ¨è¿™å„¿ã€‚ä½ æƒ³èŠä»€ä¹ˆï¼Œæˆ‘éƒ½è®¤çœŸå¬ç€ã€‚"
            elif repeated_latest:
                reply = (
                    "æˆ‘åœ¨å‘¢ï¼Œä½ æ…¢æ…¢è¯´å°±å¥½ã€‚\n"
                    "ä¸ç”¨æ€¥ç€ç»„ç»‡è¯­è¨€ï¼Œæƒ³åˆ°ä»€ä¹ˆå°±è¯´ä»€ä¹ˆã€‚"
                )
            elif has_mood_latest:
                reply = (
                    "æŠ±æŠ±ä½ ï¼Œä»Šå¤©ä¸å¼€å¿ƒä¹Ÿæ²¡å…³ç³»ï¼Œæˆ‘ä¸€ç›´éƒ½åœ¨è¿™å„¿é™ªç€ä½ ã€‚\n"
                    "ä¸ç®¡æ˜¯æƒ³åæ§½ã€æƒ³å®‰é™ï¼Œè¿˜æ˜¯åªæƒ³éšä¾¿è¯´è¯´è¯ï¼Œæˆ‘éƒ½å¬ç€ã€‚\n"
                    "æ„¿ä½ ä»Šæ™šèƒ½è¢«æ¸©æŸ”æ¥ä½ï¼Œåå¿ƒæƒ…æ—©ç‚¹é£˜èµ°ã€‚"
                )
            elif latest_user_text in confirm_keywords and has_mood_context:
                reply = (
                    "å¥½å‘€ï¼Œæˆ‘åœ¨ã€‚\n"
                    "é‚£æˆ‘ä»¬å°±è½»è½»è¯´ä¸€è¯´ï¼šä»Šå¤©è®©ä½ æœ€éš¾å—çš„é‚£ä¸€åˆ»æ˜¯ä»€ä¹ˆï¼Ÿ\n"
                    "ä½ æƒ³åˆ°å“ªä¸€å¥å°±è¯´å“ªä¸€å¥ï¼Œæˆ‘éƒ½ä¼šæ¥ç€ã€‚"
                )
            elif any(k in latest_user_text for k in relationship_keywords):
                reply = (
                    "è¿™çœŸçš„ä¼šè®©äººå¾ˆéš¾å—ï¼Œå°¤å…¶æ˜¯ä½ åœ¨ä¹ä»–çš„æ—¶å€™ã€‚\n"
                    "ä½ å…ˆåˆ«æ€¥ç€è´£æ€ªè‡ªå·±ï¼Œæˆ‘ä¼šé™ªä½ ä¸€èµ·æƒ³åŠæ³•ã€‚\n"
                    "å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘ä»¬å…ˆæŠŠåˆšåˆšå‘ç”Ÿçš„é‚£ä¸€å¹•ç†ä¸€ç†ï¼Œæˆ‘é™ªä½ æ…¢æ…¢è¯´ã€‚"
                )
            elif has_greeting_latest:
                reply = (
                    "ä½ å¥½å‘€ï¼Œæˆ‘åœ¨è¿™å„¿é™ªä½ ã€‚\n"
                    "ä»Šå¤©æƒ³èŠç‚¹ä»€ä¹ˆï¼Ÿå¼€å¿ƒçš„ã€ä¸å¼€å¿ƒçš„ï¼Œéƒ½å¯ä»¥ã€‚"
                )
            elif latest_user_text in confirm_keywords:
                reply = (
                    "å¥½å‘€ï¼Œæˆ‘é™ªä½ æ…¢æ…¢èŠã€‚\n"
                    "ä½ å¯ä»¥ä»ä»Šå¤©æœ€æƒ³è¯´çš„ä¸€ä»¶å°äº‹å¼€å§‹ã€‚"
                )
            else:
                reply = (
                    "æˆ‘åœ¨è®¤çœŸå¬ä½ è¯´ã€‚\n"
                    "å¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥å¤šè¯´ä¸€ç‚¹ç‚¹ï¼Œæˆ‘ä¼šä¸€ç›´é™ªç€ä½ ã€‚"
                )

            # æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼šæŒ‰è¡Œæ¨é€ï¼Œä¿ç•™æ•´æ´æ’ç‰ˆ
            lines = [line for line in reply.split("\n") if line]
            for idx, line in enumerate(lines):
                if idx < len(lines) - 1:
                    yield line + "\n"
                else:
                    yield line
                await asyncio.sleep(0.25)
            return

        # è®¡ç®—è¾“å…¥æ¶ˆæ¯çš„tokenæ•°é‡
        input_tokens = token_counter.count_conversation_tokens(messages)

        # GPT-4oæœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼š131072 tokens
        max_context_tokens = 131072

        # è®¡ç®—å¯ç”¨tokenæ•°é‡ï¼Œç•™å‡º2000 tokensä½œä¸ºç¼“å†²ï¼ˆè€ƒè™‘tokenè®¡æ•°å·®å¼‚ï¼‰
        available_tokens = max_context_tokens - input_tokens - 2000

        # å¦‚æœè¾“å…¥å·²ç»è¶…è¿‡é™åˆ¶ï¼ŒæŠ›å‡ºé”™è¯¯
        if available_tokens < 1:
            error_msg = f"è¾“å…¥æ¶ˆæ¯è¿‡é•¿ ({input_tokens} tokens)ï¼Œè¶…è¿‡æ¨¡å‹é™åˆ¶ ({max_context_tokens} tokens)"
            logger.error(error_msg)
            yield f"é”™è¯¯: {error_msg}"
            return

        # ç¡®å®šè¡¥å…¨tokenæ•°é‡
        if max_completion_tokens is not None:
            # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å€¼ï¼Œä½†ä¸è¶…è¿‡å¯ç”¨tokenæ•°
            completion_tokens = min(max_completion_tokens, available_tokens)
        else:
            # é»˜è®¤ä½¿ç”¨å¯ç”¨tokenæ•°çš„20%ï¼Œä½†ä¸è¶…è¿‡2000ï¼ˆæ›´ä¿å®ˆï¼‰
            default_tokens = min(int(available_tokens * 0.2), 2000)
            # ç¡®ä¿è‡³å°‘100 tokens
            completion_tokens = max(default_tokens, 100)

        # è­¦å‘Šï¼šå¦‚æœå¯ç”¨tokenå¤ªå°‘æˆ–è¾“å…¥æ¥è¿‘é™åˆ¶
        if available_tokens < 5000:
            logger.warning(f"å¯ç”¨tokenä¸è¶³: {available_tokens} (è¾“å…¥={input_tokens})ï¼Œæ¥è¿‘æ¨¡å‹é™åˆ¶")
        if input_tokens > 120000:
            logger.warning(f"è¾“å…¥tokenè¿‡å¤š: {input_tokens}ï¼Œæ¥è¿‘æ¨¡å‹é™åˆ¶131072")

        logger.info(f"Tokenç»Ÿè®¡: è¾“å…¥={input_tokens}, å¯ç”¨={available_tokens}, è¡¥å…¨={completion_tokens}")

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        openai_messages = []
        for msg in messages:
            content = []

            # æ„å»ºæ–‡æœ¬å†…å®¹ï¼šåˆå¹¶æ–‡æœ¬å’ŒéŸ³é¢‘è½¬å½•æ–‡æœ¬
            text_content = ""
            if msg.get("content"):
                text_content += msg["content"]
            if msg.get("audio_text"):
                if text_content:
                    text_content += "\n\n[éŸ³é¢‘è½¬å½•]: " + msg["audio_text"]
                else:
                    text_content = "[éŸ³é¢‘è½¬å½•]: " + msg["audio_text"]

            if text_content:
                content.append({"type": "text", "text": text_content})

            # æ·»åŠ å›¾ç‰‡å†…å®¹
            if msg.get("image_urls"):
                for img_url in msg["image_urls"]:
                    prepared_url = self._prepare_image_url(img_url)
                    if not prepared_url:
                        continue
                    content.append({
                        "type": "image_url",
                        "image_url": {"url": prepared_url}
                    })

            openai_messages.append({
                "role": msg["role"],
                "content": content if content else [{"type": "text", "text": ""}]
            })

        try:
            stream = await self.chat_client.chat.completions.create(
                model=self.deployment,
                messages=openai_messages,
                stream=True,
                max_tokens=completion_tokens,
                temperature=0.7,
            )

            async for chunk in stream:
                if chunk.choices and chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content

        except Exception as e:
            logger.error(f"OpenAIèŠå¤©è¡¥å…¨é”™è¯¯: {str(e)}", exc_info=True)
            yield f"é”™è¯¯: {str(e)}"

    async def transcribe_audio(self, audio_file_path: str) -> str:
        """è½¬å½•éŸ³é¢‘æ–‡ä»¶ä¸ºæ–‡å­—"""
        if settings.MOCK_OPENAI:
            return "[æœ¬åœ°æ¨¡æ‹Ÿè½¬å½•] è¿™æ˜¯éŸ³é¢‘è½¬æ–‡å­—çš„æµ‹è¯•ç»“æœã€‚"

        try:
            with open(audio_file_path, "rb") as audio_file:
                transcript = await self.transcribe_client.audio.transcriptions.create(
                    file=audio_file,
                    model=settings.AZURE_OPENAI_TRANSCRIBE_DEPLOYMENT,
                )
                return transcript.text
        except Exception as e:
            logger.error(f"éŸ³é¢‘è½¬å½•é”™è¯¯: {str(e)}", exc_info=True)
            return f"è½¬å½•é”™è¯¯: {str(e)}"

openai_service = OpenAIService()
